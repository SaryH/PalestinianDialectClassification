{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8606887,"sourceType":"datasetVersion","datasetId":5131996}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport soundfile as sf\n\ndef split_wav_file(input_path, output_path, duration=20, max_samples=3):\n    try:\n        os.makedirs(output_path)\n    except FileExistsError:\n        pass\n\n    for root, dirs, files in os.walk(input_path):\n        for file in files:\n            if file.endswith('.wav'):\n                input_file_path = os.path.join(root, file)\n                output_folder = os.path.relpath(root, input_path)\n                output_folder_path = os.path.join(output_path, output_folder)\n                try:\n                    os.makedirs(output_folder_path)\n                except FileExistsError:\n                    pass\n\n                y, sr = librosa.load(input_file_path, sr=None)\n                total_duration = librosa.get_duration(y=y, sr=sr)\n                counter = 0\n\n                for i in range(int(total_duration // duration)):\n                    if counter >= max_samples:\n                        break\n                    start = i * duration\n                    end = start + duration\n                    split_y = y[int(start * sr):int(end * sr)]\n                    output_file_path = os.path.join(output_folder_path, f\"{file[:-4]}_{i}.wav\")\n                    sf.write(output_file_path, split_y, sr)\n                    counter += 1\n                print(f\"Processed {file}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-09T17:39:57.036329Z","iopub.execute_input":"2024-06-09T17:39:57.036696Z","iopub.status.idle":"2024-06-09T17:39:57.072247Z","shell.execute_reply.started":"2024-06-09T17:39:57.036664Z","shell.execute_reply":"2024-06-09T17:39:57.071349Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_input_path = \"/kaggle/input/slpproject/SLP/train\"\ntrain_output_path = \"/kaggle/working/train_10s\"\ntest_input_path = \"/kaggle/input/slpproject/SLP/test\"\ntest_output_path = \"/kaggle/working/test_10s\"\n\nsplit_wav_file(train_input_path, train_output_path)\nsplit_wav_file(test_input_path, test_output_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T17:39:57.074184Z","iopub.execute_input":"2024-06-09T17:39:57.075152Z","iopub.status.idle":"2024-06-09T17:40:24.933639Z","shell.execute_reply.started":"2024-06-09T17:39:57.075117Z","shell.execute_reply":"2024-06-09T17:40:24.932667Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processed hebron_test022.wav\nProcessed hebron_train042.wav\nProcessed hebron_test025.wav\nProcessed hebron_test021.wav\nProcessed hebron_train043.wav\nProcessed hebron_test023.wav\nProcessed hebron_train045.wav\nProcessed hebron_train044.wav\nProcessed hebron_train041.wav\nProcessed hebron_test024.wav\nProcessed nablus_train045.wav\nProcessed nablus_train044.wav\nProcessed nablus_test025.wav\nProcessed nablus_test024.wav\nProcessed nablus_train042.wav\nProcessed nablus_train043.wav\nProcessed nablus_test023.wav\nProcessed nablus_train041.wav\nProcessed nablus_test022.wav\nProcessed nablus_test021.wav\nProcessed ramallah-reef_train042.wav\nProcessed ramallah-reef_test022.wav\nProcessed ramallah-reef_test021.wav\nProcessed ramallah-reef_train044.wav\nProcessed ramallah-reef_train045.wav\nProcessed ramallah-reef_test023.wav\nProcessed ramallah-reef_train041.wav\nProcessed ramallah-reef_train043.wav\nProcessed ramallah-reef_test024.wav\nProcessed ramallah-reef_test025.wav\nProcessed jerusalem_test024.wav\nProcessed jerusalem_test022.wav\nProcessed jerusalem_train044.wav\nProcessed jerusalem_train045.wav\nProcessed jerusalem_test023.wav\nProcessed jerusalem_train041.wav\nProcessed jerusalem_train043.wav\nProcessed jerusalem_train042.wav\nProcessed jerusalem_test021.wav\nProcessed jerusalem_test025.wav\nProcessed hebron_train047.wav\nProcessed hebron_train046.wav\nProcessed hebron_train048.wav\nProcessed hebron_train050.wav\nProcessed hebron_train049.wav\nProcessed nablus_train047.wav\nProcessed nablus_train046.wav\nProcessed nablus_train050.wav\nProcessed nablus_train049.wav\nProcessed nablus_train048.wav\nProcessed ramallah-reef_train047.wav\nProcessed ramallah-reef_train050.wav\nProcessed ramallah-reef_train048.wav\nProcessed ramallah-reef_train046.wav\nProcessed ramallah-reef_train049.wav\nProcessed jerusalem_train050.wav\nProcessed jerusalem_train049.wav\nProcessed jerusalem_train048.wav\nProcessed jerusalem_train046.wav\nProcessed jerusalem_train047.wav\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, TrainingArguments, Trainer\nimport torchaudio\n\n# Define a custom dataset\nclass AccentDataset(Dataset):\n    def __init__(self, directory, processor, max_length):\n        self.file_paths = []\n        self.labels = []\n        self.processor = processor\n        self.max_length = max_length\n        \n        for label, subdir in enumerate(os.listdir(directory)):\n            subdir_path = os.path.join(directory, subdir)\n            if os.path.isdir(subdir_path):\n                for file_name in os.listdir(subdir_path):\n                    if file_name.endswith('.wav'):\n                        self.file_paths.append(os.path.join(subdir_path, file_name))\n                        self.labels.append(label)\n    \n    def __len__(self):\n        return len(self.file_paths)\n    \n    def __getitem__(self, idx):\n        file_path = self.file_paths[idx]\n        label = self.labels[idx]\n        waveform, sr = torchaudio.load(file_path)\n        waveform = waveform.squeeze().numpy()\n        \n        # Concatenate audio to match max_length\n        while len(waveform) < self.max_length:\n            waveform = np.concatenate((waveform, waveform))\n        waveform = waveform[:self.max_length]\n        \n        inputs = self.processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=\"max_length\", max_length=self.max_length)\n        inputs['labels'] = torch.tensor(label, dtype=torch.long)\n        return {\n            'input_values': inputs['input_values'].squeeze(),\n            'labels': inputs['labels']\n        }\n\n# Define paths\ntrain_dir = \"/kaggle/working/train_10s\"\ntest_dir = \"/kaggle/working/test_10s\"\n\n# Determine the maximum length of audio files\nmax_length = 16000 * 20  # Limit to 10 seconds of audio\n\n# Define the number of labels\nnum_labels = 4\n\n# Load the processor and model\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\nmodel = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-base-960h\", num_labels=num_labels)\n\n# Create datasets\ntrain_dataset = AccentDataset(train_dir, processor, max_length)\ntest_dataset = AccentDataset(test_dir, processor, max_length)\n\n# DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=4, num_workers=4)\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",  # Match evaluation strategy\n    save_total_limit=1,\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,  # Reduced batch size\n    per_device_eval_batch_size=4,  # Reduced batch size\n    num_train_epochs=100,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    fp16=True,  # Enable mixed precision training\n    gradient_accumulation_steps=4,  # Simulate a larger batch size\n)\n\n# Define a simple compute_metrics function\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    return {\"accuracy\": (preds == p.label_ids).mean()}\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    compute_metrics=compute_metrics,\n)\n\n# Debugging: Check labels\nfor batch in train_loader:\n    print(\"Batch labels:\", batch['labels'])\n    assert batch['labels'].min() >= 0 and batch['labels'].max() < num_labels, \"Labels are out of range\"\n    break\n\n# Train the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T17:40:24.935246Z","iopub.execute_input":"2024-06-09T17:40:24.935708Z","iopub.status.idle":"2024-06-09T18:11:41.133919Z","shell.execute_reply.started":"2024-06-09T17:40:24.935679Z","shell.execute_reply":"2024-06-09T18:11:41.133057Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-09 17:40:32.142907: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-09 17:40:32.143019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-09 17:40:32.264882: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b2181001c94407b149f5a7b7f676c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bea5e246026b4fb49a2430633dcb96cf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da1ba4f3fad4a4ca98605747d538723"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd67c3a56704e0f90de204b8c6b24c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5a74c19291742edbf04493ebd2c5edf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6181a2afd1ec40d698dc748b440d7600"}},"metadata":{}},{"name":"stderr","text":"Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Batch labels: tensor([3, 0, 3, 0])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [400/400 30:46, Epoch 88/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>1.385926</td>\n      <td>0.245283</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.385200</td>\n      <td>1.400446</td>\n      <td>0.283019</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.351700</td>\n      <td>1.400354</td>\n      <td>0.283019</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.304200</td>\n      <td>1.352650</td>\n      <td>0.339623</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.223000</td>\n      <td>1.339346</td>\n      <td>0.320755</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.223000</td>\n      <td>1.314610</td>\n      <td>0.358491</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.164300</td>\n      <td>1.276321</td>\n      <td>0.358491</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.128600</td>\n      <td>1.292158</td>\n      <td>0.339623</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.081000</td>\n      <td>1.195709</td>\n      <td>0.415094</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.024800</td>\n      <td>1.194244</td>\n      <td>0.415094</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.019400</td>\n      <td>1.284622</td>\n      <td>0.433962</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.968400</td>\n      <td>1.195865</td>\n      <td>0.452830</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.896400</td>\n      <td>1.283544</td>\n      <td>0.433962</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.863200</td>\n      <td>1.138856</td>\n      <td>0.584906</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.880500</td>\n      <td>1.115446</td>\n      <td>0.603774</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.880500</td>\n      <td>1.093856</td>\n      <td>0.622642</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.863600</td>\n      <td>1.161322</td>\n      <td>0.603774</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.777300</td>\n      <td>1.105243</td>\n      <td>0.641509</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.783700</td>\n      <td>1.173119</td>\n      <td>0.603774</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.727000</td>\n      <td>1.036382</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.765900</td>\n      <td>1.051643</td>\n      <td>0.716981</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.624100</td>\n      <td>1.003676</td>\n      <td>0.716981</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.673600</td>\n      <td>1.001801</td>\n      <td>0.641509</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.666900</td>\n      <td>1.038924</td>\n      <td>0.679245</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.615800</td>\n      <td>0.921893</td>\n      <td>0.735849</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.615800</td>\n      <td>0.925712</td>\n      <td>0.735849</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.566200</td>\n      <td>0.951679</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.548700</td>\n      <td>0.988005</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.575400</td>\n      <td>0.913252</td>\n      <td>0.679245</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.499900</td>\n      <td>0.865075</td>\n      <td>0.716981</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.489700</td>\n      <td>0.894690</td>\n      <td>0.735849</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.483900</td>\n      <td>0.868834</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.443300</td>\n      <td>0.890991</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.447900</td>\n      <td>0.868159</td>\n      <td>0.735849</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.419400</td>\n      <td>0.978096</td>\n      <td>0.641509</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.419400</td>\n      <td>0.911432</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.422300</td>\n      <td>0.918980</td>\n      <td>0.679245</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.409200</td>\n      <td>0.931489</td>\n      <td>0.641509</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.395500</td>\n      <td>0.906390</td>\n      <td>0.679245</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.417300</td>\n      <td>0.906853</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.384800</td>\n      <td>0.915596</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.368800</td>\n      <td>0.924719</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.337300</td>\n      <td>0.921383</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.325500</td>\n      <td>0.916117</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.361400</td>\n      <td>0.912278</td>\n      <td>0.698113</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=400, training_loss=0.7171217727661133, metrics={'train_runtime': 1850.7765, 'train_samples_per_second': 3.89, 'train_steps_per_second': 0.216, 'total_flos': 1.162071293952e+18, 'train_loss': 0.7171217727661133, 'epoch': 88.88888888888889})"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\n\ndef clear_output_folders(output_paths):\n    for output_path in output_paths:\n        try:\n            shutil.rmtree(output_path)\n            print(f\"Cleared {output_path}\")\n        except FileNotFoundError:\n            print(f\"{output_path} not found\")\n\noutput_paths = [\n    \"/kaggle/working/train_10s\",\n    \"/kaggle/working/test_10s\"\n]\n\nclear_output_folders(output_paths)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:13:04.239430Z","iopub.execute_input":"2024-06-09T18:13:04.239834Z","iopub.status.idle":"2024-06-09T18:13:04.246257Z","shell.execute_reply.started":"2024-06-09T18:13:04.239804Z","shell.execute_reply":"2024-06-09T18:13:04.245259Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/train_10s not found\n/kaggle/working/test_10s not found\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport zipfile\n\ndef zip_folder(folder_path, output_path):\n    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # Walk through the directory\n        for root, dirs, files in os.walk(folder_path):\n            for file in files:\n                file_path = os.path.join(root, file)\n                # Add file to zip\n                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n\n# Example usage\nfolder_to_zip = '/kaggle/working/results'\nzip_file_name = 'result_73.zip'\nzip_folder(folder_to_zip, zip_file_name)\n\nprint(f\"Folder {folder_to_zip} zipped successfully into {zip_file_name}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:14:00.708153Z","iopub.execute_input":"2024-06-09T18:14:00.708549Z","iopub.status.idle":"2024-06-09T18:15:01.680627Z","shell.execute_reply.started":"2024-06-09T18:14:00.708517Z","shell.execute_reply":"2024-06-09T18:15:01.679641Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Folder /kaggle/working/results zipped successfully into result_73.zip\n","output_type":"stream"}]}]}